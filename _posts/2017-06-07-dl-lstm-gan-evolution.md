---
layout: post
title: "CVPR 2017: Deep learning and the new kids in class"
description: "CVPR 2017: Deep learning and the new kids in class"
comments: true
---

So here we are again to measure the presence of deep learning in the major vision conferences, with one more to the list. Here you can check the previous [posts]({{ site.url }}/deep-learning-scraping/) [of]({{ site.url }}/deep-learning-plateau/) [the]({{ site.url }}/deep-learning-takes-over-again/) [saga]({{ site.url }}/deep-learning-evolution/).<br>
<br>
Here the evolution of the results using XKCD style, as described in this [blog post]({{ site.url }}/xkcd-deep-learning/):
<br />
<img align="middle" width="500" src="{{ site.url }}/images/dl_evolution_all.png" alt="...">
<br />
<br />

So it's still growing! But we start to see a pattern here... what if we separate CVPR from the rest? Here we have it:<br>
<br />
<img align="middle" width="500" src="{{ site.url }}/images/dl_evolution_separated.png" alt="...">
<br />
<br />
Interesting! It seems like CVPR goes ahead of ECCV and ICCV here... maybe because many of those papers are resubmissions from CVPR?
<br />
<br />
In any case, it seems to be saturating... maybe people don't put deep-inducing words in the title anymore because they're taken for granted? Or because this space is being taken by the new kids in class (LSTMs and GANs)? Let's find out!
<br />
<img align="middle" width="500" src="{{ site.url }}/images/other_evolution.png" alt="...">
<br />
<br />
Well, even though they're still at more modest percentages, they're growing! But wait, what's that GAN peak in CVPR 2013? It comes from one paper titled "Representing and Discovering Adversarial Team Behaviors Using Player Roles" ðŸ˜‚. Close enough ðŸ˜….
<br />
<br />
See you in Hawaii!
